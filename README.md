
# VTF-Net: A Visual Temporal Feature Network for Robust Retinal OCT Image Segmentation
### [Project page](https://github.com/IMOP-lab/VTF-Net-Pytorch) | [Our laboratory page](https://github.com/IMOP-lab)
by Xingru Huang, Zhengyao Jiang, Zhao Huang, Yihao Guo, Jian Huang, Changpeng Yue, Jin Liu, Zhiwen Zheng, Xiaoshuai Zhang

Hangzhou Dianzi University IMOP-lab
![Figure1：Detailed network structure of our proposed VTF-NET](https://github.com/IMOP-lab/VTF-Net-Pytorch/blob/main/figures/Fig2.png)
Figure1：Detailed network structure of our proposed VTF-NET

The framework initiates with five feature maps $\{f_1, f_2, f_3, f_4, f_5\}$ generated by the ResNet backbone, successively processed through distinct components. The first four maps undergo transformation within four layers of the VTFE module, yielding enhanced outputs $\{f_1', f_2', f_3', f_4'\}$. Simultaneously, the fifth feature map $f_5$ is refined by the MSAF module, producing $f_5'$. These outputs collectively encapsulate spatiotemporal attributes and multi-resolution information, which align with the specific roles of individual network modules. The AFRP extracts and synchronizes inter-feature dependencies via RSR and ADU, optimizing temporal coherence and feature fidelity. Subsequently, the refined features pass through the EFRE, which reconstructs the final predictions, minimizing boundary ambiguity. Parameter updates occur iteratively through loss computation, ensuring optimized segmentation output with each cycle.

## Installation
The hardware configuration consisted of a desktop system equipped with two NVIDIA 3080 GPUs, an Intel E5-2690V4 CPU, and 256 GB of RAM. The software environment was constituted of Python 3.9, PyTorch 2.0.0, and CUDA 11.8, with the training framework being realized through PyTorch's DistributedDataParallel (DDP) implementation.

## Experiment

### Datesets

### baseline

### Results

## Abaltion study
