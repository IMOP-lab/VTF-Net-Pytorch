
# VTF-Net: A Visual Temporal Feature Network for Robust Retinal OCT Image Segmentation
### [Project page](https://github.com/IMOP-lab/VTF-Net-Pytorch) | [Our laboratory page](https://github.com/IMOP-lab)
by Xingru Huang, Zhengyao Jiang, Zhao Huang, Yihao Guo, Jian Huang, Changpeng Yue, Jin Liu, Zhiwen Zheng, Xiaoshuai Zhang

Hangzhou Dianzi University IMOP-lab
![Figure1：Detailed network structure of our proposed VTF-NET](https://github.com/IMOP-lab/VTF-Net-Pytorch/blob/main/figures/Fig2.png)
Figure1：Detailed network structure of our proposed VTF-NET

The framework initiates with five feature maps $\{f_1, f_2, f_3, f_4, f_5\}$ generated by the ResNet backbone, successively processed through distinct components. The first four maps undergo transformation within four layers of the VTFE module, yielding enhanced outputs $\{f_1', f_2', f_3', f_4'\}$. Simultaneously, the fifth feature map $f_5$ is refined by the MSAF module, producing $f_5'$. These outputs collectively encapsulate spatiotemporal attributes and multi-resolution information, which align with the specific roles of individual network modules. The AFRP extracts and synchronizes inter-feature dependencies via RSR and ADU, optimizing temporal coherence and feature fidelity. Subsequently, the refined features pass through the EFRE, which reconstructs the final predictions, minimizing boundary ambiguity. Parameter updates occur iteratively through loss computation, ensuring optimized segmentation output with each cycle.

## Installation
The hardware configuration consisted of a desktop system equipped with two NVIDIA 3080 GPUs, an Intel E5-2690V4 CPU, and 256 GB of RAM. The software environment was constituted of Python 3.9, PyTorch 2.0.0, and CUDA 11.8, with the training framework being realized through PyTorch's DistributedDataParallel (DDP) implementation.

## Experiment

### Datasets
|Datasets	| Quantity |  Training Set |	Validation Set | Testing Set|
|-|-|-|-|-|
|CMED-18k|10000|7200|800|2000|

### baseline
We provide GitHub links pointing to the PyTorch implementation code for all networks compared in this experiment here, so you can easily reproduce all these projects.

[UNet](https://github.com/milesial/Pytorch-UNet);[FCN8s](); [SegNet](); [PSPNet](); [ENet](); [ICNet](); [UNet+AttGate]() [DANet](); [LEDNet](); [DUNet](); [CENet](); [CGNet](); [OCNet](); [GCN](), 
### Results
![Figure2](https://github.com/IMOP-lab/VTF-Net-Pytorch/blob/main/figures/Table1.jpg)
Figure2:The results of segmentation performance of the proposed method against 14 baseline models, evaluated on the CMED-18K dataset. Metrics include dice coefficient, HD, HD95, NCC, and Kappa statistic. The highest performance values for each metric are highlighted in red, with the second highest marked in blue.

![Figure3](https://github.com/IMOP-lab/VTF-Net-Pytorch/blob/main/figures/Fig5.png)
Figure3:The visual results of our method compared to the existing 14 segmentation methods on the CMED-18k dataset.

## Abaltion study
